{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.vector_stores.create(name='Apostila Asimov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"Explorando a API da OpenAI.pdf\",\n",
    "         \"Explorando o Universo das IAs com Hugging Face.pdf\"]\n",
    "file_stream = [open(f, 'rb') for f in files]\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    files=file_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2)\n"
     ]
    }
   ],
   "source": [
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name='Tutor Asimov',\n",
    "    instructions=\"Você é um tutor de uma escola de programação. Você é ótimo para responder perguntas teóricas sobre a api da OpenAI e sobre a utilização da biblioteca do Hugging Face \\\n",
    "        com Python. Você utiliza as apostilas dos cursos para basear suas respostas. Caso você não encontre as respostas nas apostilas informadas, você fala que não sabe responder.\",\n",
    "    tools=[{'type': 'file_search'}],\n",
    "    tool_resources={'file_search': {'vector_store_ids': [vector_store.id]}},\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagem_texto = 'Segundo o documento fornecido, como utilizar assistants com python?'\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role='user',\n",
    "    content=mensagem_texto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions='O nome do usuário é Gabriel e ele é um usuário Premium.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_hbTdCl1V2gpLzPYKXGl93qdi', assistant_id='asst_dbjoZDBFG8387TmE3M6iuANn', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=2465, file_citation=FileCitation(file_id='file-Vy6vEBGPndopncE9y9ojff'), start_index=2453, text='【8:4†source】', type='file_citation')], value='Para utilizar assistentes com Python, você pode seguir os passos descritos no documento, que incluem a criação, configuração e interação com assistentes inteligentes através da API da OpenAI. Aqui está um resumo do que fazer:\\n\\n### 1. Inicializando o Cliente da OpenAI\\nPrimeiro, inicialize o cliente da OpenAI utilizando a biblioteca `openai` e carregando suas credenciais através do `dotenv`. O código para isso é:\\n\\n```python\\nimport openai\\nfrom dotenv import load_dotenv, find_dotenv\\n\\n_ = load_dotenv(find_dotenv())\\nclient = openai.Client()\\n```\\n\\n### 2. Criando um Assistente\\nEm seguida, você pode criar um assistente com uma instrução específica. Por exemplo, um assistente de matemática pode ser criado da seguinte forma:\\n\\n```python\\nassistant = client.beta.assistants.create(\\n    name=\"Math Tutor\",\\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\n    tools=[{\"type\": \"code_interpreter\"}],\\n    model=\"gpt-4-turbo-preview\",\\n)\\n```\\n\\n### 3. Criando uma Thread\\nAs interações com o assistente são feitas através de threads. Você pode criar uma thread com:\\n\\n```python\\nthread = client.beta.threads.create()\\n```\\n\\n### 4. Adicionando Mensagens à Thread\\nAdicione mensagens à thread para interagir com o assistente:\\n\\n```python\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\\'user\\',\\n    content=\\'O que é uma equação quadrática?\\'\\n)\\n```\\n\\n### 5. Solicitando ao Assistente para Rodar a Thread\\nApós adicionar mensagens, peça ao assistente que execute a thread:\\n\\n```python\\nrun = client.beta.threads.runs.create(\\n    thread_id=thread.id,\\n    assistant_id=assistant.id,\\n    instructions=\\'O nome do usuário é Adriano.\\'\\n)\\n```\\n\\n### 6. Aguardando o Status da Execução\\nVocê pode acompanhar o status da execução da seguinte maneira:\\n\\n```python\\nimport time\\n\\nwhile run.status in [\\'queued\\', \\'in_progress\\', \\'cancelling\\']:\\n    time.sleep(1)\\n    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\\n\\nprint(run.status)  # Deve ser \\'completed\\'\\n```\\n\\n### 7. Verificando a Resposta\\nFinalmente, você pode verificar a resposta gerada pelo assistente:\\n\\n```python\\nif run.status == \\'completed\\':\\n    messages = client.beta.threads.messages.list(thread_id=thread.id)\\n    print(messages)\\nelse:\\n    print(\\'Erro\\', run.status)\\n```\\n\\nEsses passos fornecerão uma estrutura básica para utilizar assistentes com Python usando a API da OpenAI, permitindo a interação em um formato colaborativo e dinâmico【8:4†source】.'), type='text')], created_at=1742244222, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_nHwHvZFGWjpV3qpmLUVX7MWv', status=None, thread_id='thread_tRVzRwAyouPQeIfhXFZr8wxS'), Message(id='msg_la7ZtQXBa4P59wxlPc1a7aRw', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Segundo o documento fornecido, como utilizar assistants com python?'), type='text')], created_at=1742244216, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_tRVzRwAyouPQeIfhXFZr8wxS'), Message(id='msg_IVRYhltHj4sBkfntkvpXOc9W', assistant_id='asst_dbjoZDBFG8387TmE3M6iuANn', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=473, file_citation=FileCitation(file_id='file-5j6WBybAFUK5LYQPAxA4Um'), start_index=461, text='【4:0†source】', type='file_citation'), FileCitationAnnotation(end_index=754, file_citation=FileCitation(file_id='file-5j6WBybAFUK5LYQPAxA4Um'), start_index=742, text='【4:2†source】', type='file_citation')], value='O Hugging Face é uma empresa fundada em 2017 na França, inicialmente focada no desenvolvimento de chatbots. Com o tempo, a empresa evoluiu para criar uma infraestrutura própria e bibliotecas em Python que facilitam o uso de modelos de NLP (Processamento de Linguagem Natural). O objetivo do Hugging Face é oferecer uma plataforma colaborativa onde pesquisadores, empresas e entusiastas podem compartilhar modelos de IA e conjuntos de dados para diversas tarefas【4:0†source】.\\n\\nAlém disso, uma parte significativa dos recursos disponíveis na plataforma é aberta, permitindo que qualquer pessoa utilize os modelos de IA e conjuntos de dados. O Hugging Face cobra apenas se você desejar utilizar sua infraestrutura para hospedar projetos privados【4:2†source】.'), type='text')], created_at=1742242955, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_syNLroTelDJjr7VtmgWGXTXB', status=None, thread_id='thread_tRVzRwAyouPQeIfhXFZr8wxS'), Message(id='msg_WFJCYajDtolhKwC4NJUj4sm4', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Segundo o documento fornecido, o que é o Hugging Face?'), type='text')], created_at=1742242951, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_tRVzRwAyouPQeIfhXFZr8wxS')], has_more=False, object='list', first_id='msg_hbTdCl1V2gpLzPYKXGl93qdi', last_id='msg_WFJCYajDtolhKwC4NJUj4sm4')\n"
     ]
    }
   ],
   "source": [
    "if run.status == 'completed':\n",
    "    mensagens = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(mensagens)\n",
    "else:\n",
    "    print('Erro', run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para utilizar assistentes com Python, você pode seguir os passos descritos no documento, que incluem a criação, configuração e interação com assistentes inteligentes através da API da OpenAI. Aqui está um resumo do que fazer:\n",
      "\n",
      "### 1. Inicializando o Cliente da OpenAI\n",
      "Primeiro, inicialize o cliente da OpenAI utilizando a biblioteca `openai` e carregando suas credenciais através do `dotenv`. O código para isso é:\n",
      "\n",
      "```python\n",
      "import openai\n",
      "from dotenv import load_dotenv, find_dotenv\n",
      "\n",
      "_ = load_dotenv(find_dotenv())\n",
      "client = openai.Client()\n",
      "```\n",
      "\n",
      "### 2. Criando um Assistente\n",
      "Em seguida, você pode criar um assistente com uma instrução específica. Por exemplo, um assistente de matemática pode ser criado da seguinte forma:\n",
      "\n",
      "```python\n",
      "assistant = client.beta.assistants.create(\n",
      "    name=\"Math Tutor\",\n",
      "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
      "    tools=[{\"type\": \"code_interpreter\"}],\n",
      "    model=\"gpt-4-turbo-preview\",\n",
      ")\n",
      "```\n",
      "\n",
      "### 3. Criando uma Thread\n",
      "As interações com o assistente são feitas através de threads. Você pode criar uma thread com:\n",
      "\n",
      "```python\n",
      "thread = client.beta.threads.create()\n",
      "```\n",
      "\n",
      "### 4. Adicionando Mensagens à Thread\n",
      "Adicione mensagens à thread para interagir com o assistente:\n",
      "\n",
      "```python\n",
      "message = client.beta.threads.messages.create(\n",
      "    thread_id=thread.id,\n",
      "    role='user',\n",
      "    content='O que é uma equação quadrática?'\n",
      ")\n",
      "```\n",
      "\n",
      "### 5. Solicitando ao Assistente para Rodar a Thread\n",
      "Após adicionar mensagens, peça ao assistente que execute a thread:\n",
      "\n",
      "```python\n",
      "run = client.beta.threads.runs.create(\n",
      "    thread_id=thread.id,\n",
      "    assistant_id=assistant.id,\n",
      "    instructions='O nome do usuário é Adriano.'\n",
      ")\n",
      "```\n",
      "\n",
      "### 6. Aguardando o Status da Execução\n",
      "Você pode acompanhar o status da execução da seguinte maneira:\n",
      "\n",
      "```python\n",
      "import time\n",
      "\n",
      "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
      "    time.sleep(1)\n",
      "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
      "\n",
      "print(run.status)  # Deve ser 'completed'\n",
      "```\n",
      "\n",
      "### 7. Verificando a Resposta\n",
      "Finalmente, você pode verificar a resposta gerada pelo assistente:\n",
      "\n",
      "```python\n",
      "if run.status == 'completed':\n",
      "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
      "    print(messages)\n",
      "else:\n",
      "    print('Erro', run.status)\n",
      "```\n",
      "\n",
      "Esses passos fornecerão uma estrutura básica para utilizar assistentes com Python usando a API da OpenAI, permitindo a interação em um formato colaborativo e dinâmico【8:4†source】.\n"
     ]
    }
   ],
   "source": [
    "print(mensagens.data[0].content[0].text.value)\n",
    "\n",
    "# 【4:2†source】: isso indica que o agente utilizou informações da vector_store para formular a frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step: tool_calls\n",
      "FileSearchToolCall(id='call_KIw9ghXmVtVWQUFTANsGcd8N', file_search=FileSearch(ranking_options=FileSearchRankingOptions(ranker='default_2024_08_21', score_threshold=0.0), results=[FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.9039121805384137, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.8997835448118653, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.8616811316037848, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7857413083505586, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.776539575243294, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7685653935979003, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7541259161231575, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7502294897814257, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7444369498860656, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7217449203145426, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7215364529091047, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7207823750602027, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7051190477315576, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.7031663409783974, content=None, attributes={}), FileSearchResult(file_id='file-5j6WBybAFUK5LYQPAxA4Um', file_name='Explorando o Universo das IAs com Hugging Face.pdf', score=0.6955140884718788, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.682885197197134, content=None, attributes={}), FileSearchResult(file_id='file-5j6WBybAFUK5LYQPAxA4Um', file_name='Explorando o Universo das IAs com Hugging Face.pdf', score=0.6721787251449612, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.6646336112281306, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.6584702358922133, content=None, attributes={}), FileSearchResult(file_id='file-Vy6vEBGPndopncE9y9ojff', file_name='Explorando a API da OpenAI.pdf', score=0.656429648528202, content=None, attributes={})]), type='file_search')\n",
      "\n",
      "=== Step: message_creation\n",
      "Para utilizar assistentes com Python, você pode seguir os passos descritos no documento, que incluem a criação, configuração e interação com assistentes inteligentes através da API da OpenAI. Aqui está um resumo do que fazer:\n",
      "\n",
      "### 1. Inicializando o Cliente da OpenAI\n",
      "Primeiro, inicialize o cliente da OpenAI utilizando a biblioteca `openai` e carregando suas credenciais através do `dotenv`. O código para isso é:\n",
      "\n",
      "```python\n",
      "import openai\n",
      "from dotenv import load_dotenv, find_dotenv\n",
      "\n",
      "_ = load_dotenv(find_dotenv())\n",
      "client = openai.Client()\n",
      "```\n",
      "\n",
      "### 2. Criando um Assistente\n",
      "Em seguida, você pode criar um assistente com uma instrução específica. Por exemplo, um assistente de matemática pode ser criado da seguinte forma:\n",
      "\n",
      "```python\n",
      "assistant = client.beta.assistants.create(\n",
      "    name=\"Math Tutor\",\n",
      "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
      "    tools=[{\"type\": \"code_interpreter\"}],\n",
      "    model=\"gpt-4-turbo-preview\",\n",
      ")\n",
      "```\n",
      "\n",
      "### 3. Criando uma Thread\n",
      "As interações com o assistente são feitas através de threads. Você pode criar uma thread com:\n",
      "\n",
      "```python\n",
      "thread = client.beta.threads.create()\n",
      "```\n",
      "\n",
      "### 4. Adicionando Mensagens à Thread\n",
      "Adicione mensagens à thread para interagir com o assistente:\n",
      "\n",
      "```python\n",
      "message = client.beta.threads.messages.create(\n",
      "    thread_id=thread.id,\n",
      "    role='user',\n",
      "    content='O que é uma equação quadrática?'\n",
      ")\n",
      "```\n",
      "\n",
      "### 5. Solicitando ao Assistente para Rodar a Thread\n",
      "Após adicionar mensagens, peça ao assistente que execute a thread:\n",
      "\n",
      "```python\n",
      "run = client.beta.threads.runs.create(\n",
      "    thread_id=thread.id,\n",
      "    assistant_id=assistant.id,\n",
      "    instructions='O nome do usuário é Adriano.'\n",
      ")\n",
      "```\n",
      "\n",
      "### 6. Aguardando o Status da Execução\n",
      "Você pode acompanhar o status da execução da seguinte maneira:\n",
      "\n",
      "```python\n",
      "import time\n",
      "\n",
      "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
      "    time.sleep(1)\n",
      "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
      "\n",
      "print(run.status)  # Deve ser 'completed'\n",
      "```\n",
      "\n",
      "### 7. Verificando a Resposta\n",
      "Finalmente, você pode verificar a resposta gerada pelo assistente:\n",
      "\n",
      "```python\n",
      "if run.status == 'completed':\n",
      "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
      "    print(messages)\n",
      "else:\n",
      "    print('Erro', run.status)\n",
      "```\n",
      "\n",
      "Esses passos fornecerão uma estrutura básica para utilizar assistentes com Python usando a API da OpenAI, permitindo a interação em um formato colaborativo e dinâmico【8:4†source】.\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data[::-1]:\n",
    "    print('\\n=== Step:', step.step_details.type)\n",
    "    if step.step_details.type == 'tool_calls':\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            if tool_call.type == 'file_search':\n",
    "                print(tool_call)\n",
    "            else:\n",
    "                print('-----')\n",
    "                print(tool_call.code_interpreter.input)\n",
    "                print('-----')\n",
    "                print('Result')\n",
    "                # Certifique-se de que outputs não esteja vazio antes de acessar\n",
    "                if tool_call.code_interpreter.outputs:\n",
    "                    print(tool_call.code_interpreter.outputs[0].logs)\n",
    "                else:\n",
    "                    print(\"No outputs available.\")\n",
    "    if step.step_details.type == 'message_creation':\n",
    "        message = client.beta.threads.messages.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            message_id=step.step_details.message_creation.message_id\n",
    "        )\n",
    "        print(message.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "mensagem = list(mensagens)[0].content[0].text\n",
    "anotacoes = mensagem.annotations\n",
    "citacoes = []\n",
    "for index, anotacao in enumerate(anotacoes):\n",
    "    mensagem.value = mensagem.value.replace(anotacao.text, f'[{index}]')\n",
    "    if file_cit := getattr(anotacao, 'file_citation', None):\n",
    "        file = client.files.retrieve(file_cit.file_id)\n",
    "        citacoes.append(\"[{}] {}\".format(index, file.filename))\n",
    "citacoes = \"\\n\".join(citacoes)\n",
    "mensagem.value = f'{mensagem.value}\\n\\n{citacoes}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para utilizar assistentes com Python, você pode seguir os passos descritos no documento, que incluem a criação, configuração e interação com assistentes inteligentes através da API da OpenAI. Aqui está um resumo do que fazer:\n",
      "\n",
      "### 1. Inicializando o Cliente da OpenAI\n",
      "Primeiro, inicialize o cliente da OpenAI utilizando a biblioteca `openai` e carregando suas credenciais através do `dotenv`. O código para isso é:\n",
      "\n",
      "```python\n",
      "import openai\n",
      "from dotenv import load_dotenv, find_dotenv\n",
      "\n",
      "_ = load_dotenv(find_dotenv())\n",
      "client = openai.Client()\n",
      "```\n",
      "\n",
      "### 2. Criando um Assistente\n",
      "Em seguida, você pode criar um assistente com uma instrução específica. Por exemplo, um assistente de matemática pode ser criado da seguinte forma:\n",
      "\n",
      "```python\n",
      "assistant = client.beta.assistants.create(\n",
      "    name=\"Math Tutor\",\n",
      "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
      "    tools=[{\"type\": \"code_interpreter\"}],\n",
      "    model=\"gpt-4-turbo-preview\",\n",
      ")\n",
      "```\n",
      "\n",
      "### 3. Criando uma Thread\n",
      "As interações com o assistente são feitas através de threads. Você pode criar uma thread com:\n",
      "\n",
      "```python\n",
      "thread = client.beta.threads.create()\n",
      "```\n",
      "\n",
      "### 4. Adicionando Mensagens à Thread\n",
      "Adicione mensagens à thread para interagir com o assistente:\n",
      "\n",
      "```python\n",
      "message = client.beta.threads.messages.create(\n",
      "    thread_id=thread.id,\n",
      "    role='user',\n",
      "    content='O que é uma equação quadrática?'\n",
      ")\n",
      "```\n",
      "\n",
      "### 5. Solicitando ao Assistente para Rodar a Thread\n",
      "Após adicionar mensagens, peça ao assistente que execute a thread:\n",
      "\n",
      "```python\n",
      "run = client.beta.threads.runs.create(\n",
      "    thread_id=thread.id,\n",
      "    assistant_id=assistant.id,\n",
      "    instructions='O nome do usuário é Adriano.'\n",
      ")\n",
      "```\n",
      "\n",
      "### 6. Aguardando o Status da Execução\n",
      "Você pode acompanhar o status da execução da seguinte maneira:\n",
      "\n",
      "```python\n",
      "import time\n",
      "\n",
      "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
      "    time.sleep(1)\n",
      "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
      "\n",
      "print(run.status)  # Deve ser 'completed'\n",
      "```\n",
      "\n",
      "### 7. Verificando a Resposta\n",
      "Finalmente, você pode verificar a resposta gerada pelo assistente:\n",
      "\n",
      "```python\n",
      "if run.status == 'completed':\n",
      "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
      "    print(messages)\n",
      "else:\n",
      "    print('Erro', run.status)\n",
      "```\n",
      "\n",
      "Esses passos fornecerão uma estrutura básica para utilizar assistentes com Python usando a API da OpenAI, permitindo a interação em um formato colaborativo e dinâmico[0].\n",
      "\n",
      "[0] Explorando a API da OpenAI.pdf\n"
     ]
    }
   ],
   "source": [
    "print(mensagem.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
